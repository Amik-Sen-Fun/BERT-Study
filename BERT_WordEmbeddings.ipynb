{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Exp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9rkLKj1lDas47HNFin7mO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amik-Sen-Fun/Technical-Project-1-NLP/blob/main/BERT_WordEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X_1bZflEJ33"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install tensorflow-text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMmNpFM7E5BO"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from bert import bert_tokenization\n",
        "import numpy as np\n",
        "from scipy.spatial import distance"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0YnzPSyi_SE"
      },
      "source": [
        "def get_model(model_url, max_seq_length):\n",
        "  inputs = dict(\n",
        "    input_word_ids=tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32),\n",
        "    input_mask=tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32),\n",
        "    input_type_ids=tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32),\n",
        "    )\n",
        "\n",
        "  muril_layer = hub.KerasLayer(model_url, trainable=True)\n",
        "  outputs = muril_layer(inputs)\n",
        "\n",
        "  assert 'sequence_output' in outputs\n",
        "  assert 'pooled_output' in outputs\n",
        "  assert 'encoder_outputs' in outputs\n",
        "  assert 'default' in outputs\n",
        "  return tf.keras.Model(inputs=inputs,outputs=outputs[\"pooled_output\"]), muril_layer"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2KGB0w8ECDD"
      },
      "source": [
        "max_seq_length = 128\n",
        "muril_model, muril_layer = get_model(\n",
        "    model_url=\"https://tfhub.dev/google/MuRIL/1\", max_seq_length=max_seq_length)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ec0Keh0otw_"
      },
      "source": [
        "vocab_file = muril_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = muril_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzvMyhB5o288"
      },
      "source": [
        "def create_input(input_strings, tokenizer, max_seq_length):\n",
        "  input_ids_all, input_mask_all, input_type_ids_all = [], [], []\n",
        "  for input_string in input_strings:\n",
        "    input_tokens = [\"[CLS]\"] + tokenizer.tokenize(input_string) + [\"[SEP]\"]\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n",
        "    sequence_length = min(len(input_ids), max_seq_length)\n",
        "    \n",
        "    if len(input_ids) >= max_seq_length:\n",
        "      input_ids = input_ids[:max_seq_length]\n",
        "    else:\n",
        "      input_ids = input_ids + [0] * (max_seq_length - len(input_ids))\n",
        "\n",
        "    input_mask = [1] * sequence_length + [0] * (max_seq_length - sequence_length)\n",
        "\n",
        "    input_ids_all.append(input_ids)\n",
        "    input_mask_all.append(input_mask)\n",
        "    input_type_ids_all.append([0] * max_seq_length)\n",
        "  \n",
        "  return np.array(input_ids_all), np.array(input_mask_all), np.array(input_type_ids_all)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g83K0WZco6bB"
      },
      "source": [
        "def encode(input_text):\n",
        "  input_ids, input_mask, input_type_ids = create_input(input_text, \n",
        "                                                       tokenizer, \n",
        "                                                       max_seq_length)\n",
        "  inputs = dict(\n",
        "      input_word_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      input_type_ids=input_type_ids,\n",
        "  )\n",
        "  return muril_model(inputs)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwKn6q-Go9wm"
      },
      "source": [
        "sentences = [\"दोस्त\", \"मित्र\", \"शत्रु\"]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7wXUmxopABd"
      },
      "source": [
        "embeddings = encode(sentences)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0_kq05TqRpM"
      },
      "source": [
        "preprocessor = hub.KerasLayer(\"https://tfhub.dev/google/MuRIL_preprocess/1\")\n",
        "inputs = preprocessor(sentences)\n",
        "outputs = muril_layer(inputs)\n",
        "outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_83RxsSpGs-",
        "outputId": "2c9abe6a-c14f-40bb-b2f7-bf7e4b11c7d3"
      },
      "source": [
        "dst_2 = distance.euclidean(np.array(embeddings[1]), \n",
        "                           np.array(embeddings[2]))\n",
        "print(\"Distance between {} & {} is {}\".format(sentences[1],\n",
        "                                                sentences[2],\n",
        "                                                dst_2))\n",
        "\n",
        "dst_1 = distance.euclidean(np.array(embeddings[0]), \n",
        "                           np.array(embeddings[1]))\n",
        "print(\"Distance between {} & {} is {}\".format(sentences[0],\n",
        "                                                sentences[1],\n",
        "                                                dst_1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance between मित्र & शत्रु is 0.011569398455321789\n",
            "Distance between दोस्त & मित्र is 0.009007965214550495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey7Tkyc3qyxn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}